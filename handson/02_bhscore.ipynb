{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Tutorial for Brain Hierarchy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a hands-on tutorial for brain hierarchy (BH) score ([Nonaka et al., 2021](https://doi.org/10.1016/j.isci.2021.103013)).\n",
    "BH score quantifies the hierarchical correspondence between the brain and visual neural network models based on decoding and encoding analyses.\n",
    "In this tutorial, we will demonstrate how to compute BH score using decoding and encoding accuracies of 29 DNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code block to install Python packages required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install hdf5storage\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, t\n",
    "import pandas as pd\n",
    "from hdf5storage import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset used in this notebook.\n",
    "Please ignore it if you have already downloaded the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O decoding_accuracy.zip https://ndownloader.figshare.com/files/24132263   # Total size: 88.41MB\n",
    "!wget -O encoding_accuracy.zip https://figshare.com/ndownloader/files/32116400   # Total size: 264.17MB\n",
    "!unzip -q decoding_accuracy.zip\n",
    "!unzip -q encoding_accuracy.zip\n",
    "!mkdir data\n",
    "!mv decoding_accuracy encoding_accuracy data/\n",
    "!curl -O https://raw.githubusercontent.com/KamitaniLab/BHscore/master/settings.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define settings for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data settings\n",
    "\n",
    "# Subjects and ROIs\n",
    "subjects = [\"sub-01\", \"sub-02\", \"sub-03\"]\n",
    "rois = [\"V1\", \"V2\", \"V3\", \"V4\", \"HVC\"]\n",
    "\n",
    "# DNNs\n",
    "with open(\"settings.json\", \"r\") as f:\n",
    "    dnns = json.load(f)[\"dnns\"]\n",
    "\n",
    "decoding_accuracy_dir = Path(\"data/decoding_accuracy/ImageNetTest\")\n",
    "encoding_accuracy_dir = Path(\"data/encoding_accuracy/ImageNetTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading decoding and encoding prediction accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load decoding and encoding prediction accuracies from the downloaded data.\n",
    "BH scores are calculated from the decoding and encoding prediction accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_accuracy = pd.DataFrame(columns=[\"network\", \"layer\", \"roi\", \"accuracy\"])\n",
    "encoding_accuracy = pd.DataFrame(columns=[\"network\", \"layer\", \"roi\", \"accuracy\"])\n",
    "\n",
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    dec_acc_array = np.zeros((len(layers), len(rois)))\n",
    "    enc_acc_array = np.zeros((len(layers), len(rois)))\n",
    "\n",
    "    for i, lay in enumerate(layers):\n",
    "        for j, roi in enumerate(rois):\n",
    "\n",
    "            # Pool decoding accuracies across subjects\n",
    "            dec_acc_pooled = []\n",
    "            enc_acc_pooled = []\n",
    "            for sub in subjects:\n",
    "                dec_acc_file = decoding_accuracy_dir / dnn['dir'] / lay / sub / roi / 'accuracy.mat'\n",
    "                enc_acc_file = encoding_accuracy_dir / dnn['dir'] / lay / sub / roi / 'accuracy.mat'\n",
    "\n",
    "                dec_acc = loadmat(str(dec_acc_file))['accuracy'].ravel()\n",
    "                enc_acc = loadmat(str(enc_acc_file))['accuracy'].ravel()\n",
    "\n",
    "                dec_acc_pooled.append(dec_acc)\n",
    "                enc_acc_pooled.append(enc_acc)\n",
    "\n",
    "            dec_acc_pooled = np.hstack(dec_acc_pooled)\n",
    "            enc_acc_pooled = np.hstack(enc_acc_pooled)\n",
    "\n",
    "            df_dec = pd.DataFrame({\n",
    "                \"network\": dnn_name,\n",
    "                \"layer\": lay,\n",
    "                \"roi\": roi,\n",
    "                \"accuracy\": [dec_acc_pooled]\n",
    "            })\n",
    "            df_enc = pd.DataFrame({\n",
    "                \"network\": dnn_name,\n",
    "                \"layer\": lay,\n",
    "                \"roi\": roi,\n",
    "                \"accuracy\": [enc_acc_pooled]\n",
    "            })\n",
    "\n",
    "            decoding_accuracy = pd.concat([decoding_accuracy, df_dec], ignore_index=True)\n",
    "            encoding_accuracy = pd.concat([encoding_accuracy, df_enc], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating BH scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to calculate BH scores (original code: https://github.com/KamitaniLab/BHscore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate BH score\n",
    "# https://github.com/KamitaniLab/BHscore \n",
    "\n",
    "\n",
    "def compute_bhscore(\n",
    "        predacc_list: List[np.ndarray],\n",
    "        pval: float = 0.05,\n",
    "        return_tops: bool = False\n",
    "    ) -> Union[float, Tuple[float, List[np.ndarray]]]:\n",
    "    \"\"\"Compute a BH score of a given DNN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predacc_list : list of arrays\n",
    "        List of prediction accuracies for a DNN. Each array contains\n",
    "        prediction accuracies of individual units in a layer, formed as an\n",
    "         array of ROIs/layers x units/voxels.\n",
    "    pval : float, default = 0.05\n",
    "        P-value threshold in unit selection.\n",
    "    return_tops : bool, default = False\n",
    "        Returns top ROIs/layers if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bhscore : float\n",
    "    top_rois: list of arrays\n",
    "    \"\"\"\n",
    "\n",
    "    tops = []\n",
    "    for predacc in predacc_list:\n",
    "        # if prediction accuracy is nan, convert it to zero\n",
    "        predacc[np.isnan(predacc)] = 0\n",
    "\n",
    "        # for each CNN units, search roi/layer which has the highest prediction accuracy\n",
    "        pred_max = np.max(predacc, axis=0)\n",
    "        pred_max_ind = np.argmax(predacc, axis=0)\n",
    "\n",
    "        # compute p value of the highest decoding accuracy\n",
    "        tmp = np.sqrt((50 - 2) * (1 - pred_max ** 2))\n",
    "        tmp = pred_max * tmp\n",
    "        pvals = 2 * (1 - t.cdf(tmp, df=50 - 2))\n",
    "\n",
    "        # keep unit with p value < threshold and acc > 0\n",
    "        threshold = pvals < pval\n",
    "        plus_unit = pred_max > 0\n",
    "        select_unit_ind = np.logical_and(threshold, plus_unit)\n",
    "        pred_max_ind = pred_max_ind[select_unit_ind]\n",
    "\n",
    "        tops.append(pred_max_ind)\n",
    "\n",
    "    # get layer numbers of each unit. concatenate best ROIs/layers for all layers\n",
    "    layer_numbers = []\n",
    "    tops_flatten = []\n",
    "    for i_br, br in enumerate(tops):\n",
    "        layer_numbers.extend(np.repeat(i_br + 1, len(br)))\n",
    "        tops_flatten.extend(br)\n",
    "\n",
    "    # compute Spearman's rank correlation\n",
    "    bhscore, _ = spearmanr(layer_numbers, tops_flatten)\n",
    "\n",
    "    if return_tops:\n",
    "        return bhscore, tops\n",
    "    else:\n",
    "        return bhscore\n",
    "\n",
    "\n",
    "def compute_bhscore_layerselect(\n",
    "        predacc_list: List[np.ndarray],\n",
    "        pval: float = 0.05,\n",
    "        n_layers: int = 5,\n",
    "        n_repeat: int = 100,\n",
    "        return_top_rois: bool = False\n",
    "    ) -> Union[float, Tuple[float, List[List[np.ndarray]]]]:\n",
    "    \"\"\"Compute a BH score of a given DNN, random layer selection version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predacc_list : list of arrays\n",
    "        List of prediction accuracies for a DNN. Each array contains\n",
    "        prediction accuracies of individual units in a layer, formed as an\n",
    "         array of ROIs x units.\n",
    "    pval : float, default = 0.05\n",
    "        P-value threshold in unit selection.\n",
    "    n_layers : int, default = 5\n",
    "        The number of layers used to compute the BH score. Note that the first\n",
    "        and last layers are always included in the computation. Thus,\n",
    "        (n_layers - 2) layers are randomly selected from the representative\n",
    "        layers except the first and last ones.\n",
    "    n_repeat : int, default = 100\n",
    "        The number of random layer selection.\n",
    "    return_top_rois : bool, default = False\n",
    "        Returns top ROIs if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bhscore_list : arary of float\n",
    "    top_rois_list : list of list of arrays\n",
    "    \"\"\"\n",
    "\n",
    "    bhscore_list = np.zeros(n_repeat)\n",
    "    top_rois_list = []\n",
    "    for i_s in range(n_repeat):\n",
    "        # sample layers\n",
    "        sample_index = np.random.choice(np.arange(1, len(predacc_list)-1), size=n_layers - 2, replace=False)\n",
    "        sample_index = np.sort(sample_index)\n",
    "        predacc_list_sampled = [predacc_list[0]] + [predacc_list[i] for i in sample_index] + [predacc_list[-1]]\n",
    "\n",
    "        bhscore, top_rois = compute_bhscore(predacc_list_sampled, pval, return_tops=True)\n",
    "        bhscore_list[i_s] = bhscore\n",
    "        top_rois_list.append(top_rois)\n",
    "\n",
    "    if return_top_rois:\n",
    "        return bhscore_list, top_rois_list\n",
    "    else:\n",
    "        return bhscore_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ccalculate BH scores of each DNN using the function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_decoding = {}  # Decoding-based BH scores\n",
    "bhscore_encoding = {}  # Encoding-based BH scores\n",
    "bhscore = {}           # Average BH scores\n",
    "\n",
    "decoding_top_rois = {}\n",
    "encoding_top_layers = {}\n",
    "\n",
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    # Decoding-based BH score\n",
    "    dec_pred_acc = []\n",
    "    for i, lay in enumerate(layers):\n",
    "        df = np.stack([\n",
    "            list(decoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for roi in rois\n",
    "        ])\n",
    "        dec_pred_acc.append(df)\n",
    "    #bhscore_dec, top_rois = compute_bhscore(dec_pred_acc, return_tops=True)\n",
    "    bhscore_dec = compute_bhscore_layerselect(dec_pred_acc, n_layers=5, n_repeat=100)\n",
    "    bhscore_dec = np.mean(bhscore_dec)\n",
    "\n",
    "    # Encoding-based BH score\n",
    "    enc_pred_acc = []\n",
    "    for i, roi in enumerate(rois):\n",
    "        df = np.stack([\n",
    "            list(encoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for lay in layers\n",
    "        ])\n",
    "        enc_pred_acc.append(df)\n",
    "    bhscore_enc = compute_bhscore(enc_pred_acc)\n",
    "\n",
    "    bhscore_decoding[dnn_name] = bhscore_dec\n",
    "    bhscore_encoding[dnn_name] = bhscore_enc\n",
    "    bhscore[dnn_name] = np.mean([bhscore_dec, bhscore_enc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying BH scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the ranking of BH scores for the 29 DNNs (Figure 3 in [the original paper](https://doi.org/10.1016/j.isci.2021.103013)).\n",
    "Note that the results may slightly differ from the original paper due to some randomness in the calculation of BH scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BH score ranking\n",
    "nets = np.array([n for n in bhscore.keys()])\n",
    "bhscores = np.array([s for s in bhscore.values()])\n",
    "\n",
    "ranking_index = np.argsort(bhscores)[::-1]\n",
    "nets = nets[ranking_index]\n",
    "bhscores = bhscores[ranking_index]\n",
    "\n",
    "for net, score in zip(nets, bhscores):\n",
    "    print('{}: {}'.format(net, score))\n",
    "\n",
    "# Bar chart\n",
    "fig = plt.figure(figsize=(8, 14))\n",
    "\n",
    "ypos = range(nets.shape[0])[::-1]\n",
    "\n",
    "plt.barh(ypos, bhscores)\n",
    "\n",
    "plt.title('BH score')\n",
    "\n",
    "plt.yticks(ypos, nets)\n",
    "plt.ylim([-0.5, nets.shape[0] - 0.5])\n",
    "\n",
    "for yp, bhs in zip(ypos, bhscores):\n",
    "    plt.text(\n",
    "        bhs - 0.005, yp, '%.2f' % bhs, color='white',\n",
    "        horizontalalignment='right',\n",
    "        verticalalignment='center'\n",
    "    )\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of most preditive ROIs/layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the distribution of the most predictive ROIs/layers for each DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot the distribution of the most predictive ROIs/layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makefig_top_distribution(accuracy: List[np.ndarray], layers: List[str], rois: List[str], dnn_name: str, type: str = \"decoding\"):\n",
    "    \"\"\"Make a figure of the distribution of top ROIs/layers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    accuracy : list of arrays\n",
    "        List of prediction accuracies for a DNN.\n",
    "    layers : list of str\n",
    "        List of layer names.\n",
    "    rois : list of str\n",
    "        List of ROI names.\n",
    "    dnn_name : str\n",
    "        DNN name.\n",
    "    type : str, default = \"decoding\"\n",
    "        Type of analysis. \"decoding\" or \"encoding\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "\n",
    "    bh_score, tops = compute_bhscore(accuracy, pval=0.05, return_tops=True)\n",
    "\n",
    "    n_layers = len(layers)\n",
    "    n_rois = len(rois)\n",
    "\n",
    "    if type == \"decoding\":\n",
    "        components = layers\n",
    "        n_components = len(components)\n",
    "        features = rois\n",
    "    elif type == \"encoding\":\n",
    "        components = rois\n",
    "        n_components = len(components)\n",
    "        features = layers\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 1 * n_components))\n",
    "\n",
    "    for i, (comp, top) in enumerate(zip(components, tops)):\n",
    "        y = np.array([\n",
    "            np.sum(top == i)\n",
    "            for i, _ in enumerate(features)\n",
    "        ])\n",
    "        y = y / np.size(top)\n",
    "\n",
    "        x = np.arange(len(features))\n",
    "\n",
    "        plt.subplot(n_components, 1, n_components - i)\n",
    "\n",
    "        plt.bar(x, y, width=0.8, color='gray')\n",
    "        plt.xticks([])\n",
    "        if i == 0:\n",
    "            plt.xticks(x, labels=features, fontsize=9)\n",
    "        plt.ylim([0, 1])\n",
    "        plt.yticks([])\n",
    "        plt.text(-0.5, 0.75, comp, fontsize=12)\n",
    "\n",
    "        if i == n_components - 1:\n",
    "            plt.title('{} {} BH score = {:.2f}'.format(dnn_name, type, bh_score), fontsize=12)\n",
    "\n",
    "        # Box off\n",
    "        ax = plt.gca()\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the most predictive ROIs/layers for \"AlexNet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"AlexNet\"\n",
    "\n",
    "layers = dnns[network]['layers']\n",
    "rois = [\"V1\", \"V2\", \"V3\", \"V4\", \"HVC\"]\n",
    "\n",
    "# Decoding-based BH score\n",
    "dec_pred_acc = []\n",
    "for i, lay in enumerate(layers):\n",
    "    acc = np.stack([\n",
    "        list(decoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "        for roi in rois\n",
    "    ])\n",
    "    dec_pred_acc.append(acc)\n",
    "\n",
    "makefig_top_distribution(dec_pred_acc, dnn['layers'], rois, dnn_name, type=\"decoding\")\n",
    "\n",
    "# Encoding-based BH score\n",
    "enc_pred_acc = []\n",
    "for i, roi in enumerate(rois):\n",
    "    acc = np.stack([\n",
    "        list(encoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "        for lay in layers\n",
    "    ])\n",
    "    enc_pred_acc.append(acc)\n",
    "bhscore_enc = compute_bhscore(enc_pred_acc)\n",
    "\n",
    "makefig_top_distribution(enc_pred_acc, dnn['layers'], rois, dnn_name, type=\"encoding\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the most predictive ROIs/layers for all DNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = [\"V1\", \"V2\", \"V3\", \"V4\", \"HVC\"]\n",
    "\n",
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    # Decoding-based BH score\n",
    "    dec_pred_acc = []\n",
    "    for i, lay in enumerate(layers):\n",
    "        acc = np.stack([\n",
    "            list(decoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for roi in rois\n",
    "        ])\n",
    "        dec_pred_acc.append(acc)\n",
    "\n",
    "    makefig_top_distribution(dec_pred_acc, dnn['layers'], rois, dnn_name, type=\"decoding\")\n",
    "\n",
    "    # Encoding-based BH score\n",
    "    enc_pred_acc = []\n",
    "    for i, roi in enumerate(rois):\n",
    "        acc = np.stack([\n",
    "            list(encoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for lay in layers\n",
    "        ])\n",
    "        enc_pred_acc.append(acc)\n",
    "    bhscore_enc = compute_bhscore(enc_pred_acc)\n",
    "\n",
    "    makefig_top_distribution(enc_pred_acc, dnn['layers'], rois, dnn_name, type=\"encoding\")\n",
    "\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

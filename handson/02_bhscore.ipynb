{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Tutorial for Brain Hierarchy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a hands-on tutorial for brain hierarchy (BH) score ([Nonaka et al., 2021](https://doi.org/10.1016/j.isci.2021.103013)).\n",
    "BH score quantifies the hierarchical correspondence between the brain and visual neural network models based on decoding and encoding analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "Please run the following code blocks to set up analysis environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install hdf5storage\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, t\n",
    "import pandas as pd\n",
    "from hdf5storage import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download decoding and encoding accuracies required to calculate BH scores.\n",
    "Please skip this section if you have already downloaded the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O decoding_accuracy.zip https://ndownloader.figshare.com/files/24132263   # Total size: 88.41MB\n",
    "!wget -O encoding_accuracy.zip https://figshare.com/ndownloader/files/32116400   # Total size: 264.17MB\n",
    "!unzip -q decoding_accuracy.zip\n",
    "!unzip -q encoding_accuracy.zip\n",
    "!mkdir data\n",
    "!mv decoding_accuracy encoding_accuracy data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://raw.githubusercontent.com/KamitaniLab/BHscore/master/settings.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define settings for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data settings\n",
    "\n",
    "# Subjects and ROIs\n",
    "subjects = [\"sub-01\", \"sub-02\", \"sub-03\"]\n",
    "rois = [\"V1\", \"V2\", \"V3\", \"V4\", \"HVC\"]\n",
    "\n",
    "# DNNs\n",
    "with open(\"settings.json\", \"r\") as f:\n",
    "    dnns = json.load(f)[\"dnns\"]\n",
    "\n",
    "decoding_accuracy_dir = Path(\"data/decoding_accuracy/ImageNetTest\")\n",
    "encoding_accuracy_dir = Path(\"data/encoding_accuracy/ImageNetTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading decoding and encoding prediction accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate BH scores, we need to load decoding and encoding prediction accuracies.\n",
    "Here we loads decoding and encoding prediction accuracies from the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_accuracy = pd.DataFrame(columns=[\"network\", \"layer\", \"roi\", \"accuracy\"])\n",
    "encoding_accuracy = pd.DataFrame(columns=[\"network\", \"layer\", \"roi\", \"accuracy\"])\n",
    "\n",
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    dec_acc_array = np.zeros((len(layers), len(rois)))\n",
    "    enc_acc_array = np.zeros((len(layers), len(rois)))\n",
    "\n",
    "    for i, lay in enumerate(layers):\n",
    "        for j, roi in enumerate(rois):\n",
    "\n",
    "            # Pool decoding accuracies across subjects\n",
    "            dec_acc_pooled = []\n",
    "            enc_acc_pooled = []\n",
    "            for sub in subjects:\n",
    "                dec_acc_file = decoding_accuracy_dir / dnn['dir'] / lay / sub / roi / 'accuracy.mat'\n",
    "                enc_acc_file = encoding_accuracy_dir / dnn['dir'] / lay / sub / roi / 'accuracy.mat'\n",
    "\n",
    "                dec_acc = loadmat(str(dec_acc_file))['accuracy'].ravel()\n",
    "                enc_acc = loadmat(str(enc_acc_file))['accuracy'].ravel()\n",
    "\n",
    "                dec_acc_pooled.append(dec_acc)\n",
    "                enc_acc_pooled.append(enc_acc)\n",
    "\n",
    "            dec_acc_pooled = numpy.hstack(dec_acc_pooled)\n",
    "            enc_acc_pooled = numpy.hstack(enc_acc_pooled)\n",
    "\n",
    "            df_dec = pd.DataFrame({\n",
    "                \"network\": dnn_name,\n",
    "                \"layer\": lay,\n",
    "                \"roi\": roi,\n",
    "                \"accuracy\": [dec_acc_pooled]\n",
    "            })\n",
    "            df_enc = pd.DataFrame({\n",
    "                \"network\": dnn_name,\n",
    "                \"layer\": lay,\n",
    "                \"roi\": roi,\n",
    "                \"accuracy\": [enc_acc_pooled]\n",
    "            })\n",
    "\n",
    "            decoding_accuracy = pd.concat([decoding_accuracy, df_dec], ignore_index=True)\n",
    "            encoding_accuracy = pd.concat([encoding_accuracy, df_enc], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating BH scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define functions to calculate BH scores (original code: https://github.com/KamitaniLab/BHscore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate BH score\n",
    "# https://github.com/KamitaniLab/BHscore \n",
    "\n",
    "\n",
    "def compute_bhscore(predacc_list, pval=0.05, return_tops=False):\n",
    "    \"\"\"Compute a BH score of a given DNN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predacc_list : list of arrays\n",
    "        List of prediction accuracies for a DNN. Each array contains\n",
    "        prediction accuracies of individual units in a layer, formed as an\n",
    "         array of ROIs/layers x units/voxels.\n",
    "    pval : float, default = 0.05\n",
    "        P-value threshold in unit selection.\n",
    "    return_tops : bool, default = False\n",
    "        Returns top ROIs/layers if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bhscore : float\n",
    "    top_rois: list of arrays\n",
    "    \"\"\"\n",
    "\n",
    "    tops = []\n",
    "    for predacc in predacc_list:\n",
    "        # if prediction accuracy is nan, convert it to zero\n",
    "        predacc[np.isnan(predacc)] = 0\n",
    "\n",
    "        # for each CNN units, search roi/layer which has the highest prediction accuracy\n",
    "        pred_max = np.max(predacc, axis=0)\n",
    "        pred_max_ind = np.argmax(predacc, axis=0)\n",
    "\n",
    "        # compute p value of the highest decoding accuracy\n",
    "        tmp = np.sqrt((50 - 2) * (1 - pred_max ** 2))\n",
    "        tmp = pred_max * tmp\n",
    "        pvals = 2 * (1 - t.cdf(tmp, df=50 - 2))\n",
    "\n",
    "        # keep unit with p value < threshold and acc > 0\n",
    "        threshold = pvals < pval\n",
    "        plus_unit = pred_max > 0\n",
    "        select_unit_ind = np.logical_and(threshold, plus_unit)\n",
    "        pred_max_ind = pred_max_ind[select_unit_ind]\n",
    "\n",
    "        tops.append(pred_max_ind)\n",
    "\n",
    "    # get layer numbers of each unit. concatenate best ROIs/layers for all layers\n",
    "    layer_numbers = []\n",
    "    tops_flatten = []\n",
    "    for i_br, br in enumerate(tops):\n",
    "        layer_numbers.extend(np.repeat(i_br + 1, len(br)))\n",
    "        tops_flatten.extend(br)\n",
    "\n",
    "    # compute Spearman's rank correlation\n",
    "    bhscore, _ = spearmanr(layer_numbers, tops_flatten)\n",
    "\n",
    "    if return_tops:\n",
    "        return bhscore, tops\n",
    "    else:\n",
    "        return bhscore\n",
    "\n",
    "\n",
    "def compute_bhscore_layerselect(predacc_list, pval=0.05, n_layers=5,\n",
    "                                n_repeat=100, return_top_rois=False):\n",
    "    \"\"\"Compute a BH score of a given DNN, random layer selection version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predacc_list : list of arrays\n",
    "        List of prediction accuracies for a DNN. Each array contains\n",
    "        prediction accuracies of individual units in a layer, formed as an\n",
    "         array of ROIs x units.\n",
    "    pval : float, default = 0.05\n",
    "        P-value threshold in unit selection.\n",
    "    n_layers : int, default = 5\n",
    "        The number of layers used to compute the BH score. Note that the first\n",
    "        and last layers are always included in the computation. Thus,\n",
    "        (n_layers - 2) layers are randomly selected from the representative\n",
    "        layers except the first and last ones.\n",
    "    n_repeat : int, default = 100\n",
    "        The number of random layer selection.\n",
    "    return_top_rois : bool, default = False\n",
    "        Returns top ROIs if True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bhscore_list : arary of float\n",
    "    top_rois_list : list of list of arrays\n",
    "    \"\"\"\n",
    "\n",
    "    bhscore_list = np.zeros(n_repeat)\n",
    "    top_rois_list = []\n",
    "    for i_s in range(n_repeat):\n",
    "        # sample layers\n",
    "        sample_index = np.random.choice(np.arange(1, len(predacc_list)-1), size=n_layers - 2, replace=False)\n",
    "        sample_index = np.sort(sample_index)\n",
    "        predacc_list_sampled = [predacc_list[0]] + [predacc_list[i] for i in sample_index] + [predacc_list[-1]]\n",
    "\n",
    "        bhscore, top_rois = compute_bhscore(predacc_list_sampled, pval, return_tops=True)\n",
    "        bhscore_list[i_s] = bhscore\n",
    "        top_rois_list.append(top_rois)\n",
    "\n",
    "    if return_top_rois:\n",
    "        return bhscore_list, top_rois_list\n",
    "    else:\n",
    "        return bhscore_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions, we calculate BH scores of each DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_decoding = {}\n",
    "bhscore_encoding = {}\n",
    "bhscore = {}\n",
    "\n",
    "decoding_top_rois = {}\n",
    "encoding_top_layers = {}\n",
    "\n",
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    # decoding\n",
    "    dec_pred_acc = []\n",
    "    for i, lay in enumerate(layers):\n",
    "        df = np.stack([\n",
    "            list(decoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for roi in rois\n",
    "        ])\n",
    "        dec_pred_acc.append(df)\n",
    "    #bhscore_dec, top_rois = compute_bhscore(dec_pred_acc, return_tops=True)\n",
    "    bhscore_dec = compute_bhscore_layerselect(dec_pred_acc, n_layers=5, n_repeat=100)\n",
    "    bhscore_dec = np.mean(bhscore_dec)\n",
    "\n",
    "    # encoding\n",
    "    enc_pred_acc = []\n",
    "    for i, roi in enumerate(rois):\n",
    "        df = np.stack([\n",
    "            list(encoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for lay in layers\n",
    "        ])\n",
    "        enc_pred_acc.append(df)\n",
    "    bhscore_enc = compute_bhscore(enc_pred_acc)\n",
    "\n",
    "    bhscore_decoding[dnn_name] = bhscore_dec\n",
    "    bhscore_encoding[dnn_name] = bhscore_enc\n",
    "    bhscore[dnn_name] = np.mean([bhscore_dec, bhscore_enc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhscore_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying BH scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BH score ranking\n",
    "nets = np.array([n for n in bhscore.keys()])\n",
    "bhscores = np.array([s for s in bhscore.values()])\n",
    "\n",
    "ranking_index = np.argsort(bhscores)[::-1]\n",
    "nets = nets[ranking_index]\n",
    "bhscores = bhscores[ranking_index]\n",
    "\n",
    "for net, score in zip(nets, bhscores):\n",
    "    print('{}: {}'.format(net, score))\n",
    "\n",
    "# Bar chart\n",
    "fig = plt.figure(figsize=(8, 14))\n",
    "\n",
    "ypos = range(nets.shape[0])[::-1]\n",
    "\n",
    "plt.barh(ypos, bhscores)\n",
    "\n",
    "plt.title('BH score')\n",
    "\n",
    "plt.yticks(ypos, nets)\n",
    "plt.ylim([-0.5, nets.shape[0] - 0.5])\n",
    "\n",
    "for yp, bhs in zip(ypos, bhscores):\n",
    "    plt.text(\n",
    "        bhs - 0.005, yp, '%.2f' % bhs, color='white',\n",
    "        horizontalalignment='right',\n",
    "        verticalalignment='center'\n",
    "    )\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of most preditive ROIs/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makefig_top_roi_distribution(decoding_accuracy, layers, dnn_name):\n",
    "\n",
    "    bh_score, top_rois = compute_bhscore(decoding_accuracy, pval=0.05, return_tops=True)\n",
    "    n_layers = len(layers)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 1.5 * n_layers))\n",
    "\n",
    "    for i, (layer, top_roi) in enumerate(zip(layers, top_rois)):\n",
    "\n",
    "        y = np.array([\n",
    "            np.sum(top_roi == 0),\n",
    "            np.sum(top_roi == 1),\n",
    "            np.sum(top_roi == 2),\n",
    "            np.sum(top_roi == 3),\n",
    "            np.sum(top_roi == 4),\n",
    "        ])\n",
    "        y = y / np.size(top_roi)\n",
    "\n",
    "        plt.subplot(n_layers, 1, n_layers - i)\n",
    "\n",
    "        plt.bar([0, 1, 2, 3, 4], y, width=0.8, color='gray')\n",
    "        plt.xticks([])\n",
    "        if i == 0:\n",
    "            plt.xticks([0, 1, 2, 3, 4], labels=['V1', 'V2', 'V3', 'V4', 'HVC'])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.yticks([])\n",
    "        plt.text(-0.5, 0.75, layer, fontsize=16)\n",
    "\n",
    "        if i == len(layers) - 1:\n",
    "            plt.title('{} BH score = {:.2f}'.format(dnn_name, bh_score), fontsize=16)\n",
    "\n",
    "        # Box off\n",
    "        ax = plt.gca()\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dnn_name, dnn in dnns.items():\n",
    "\n",
    "    layers = dnn['layers']\n",
    "\n",
    "    dec_pred_acc = []\n",
    "    for i, lay in enumerate(layers):\n",
    "        df = np.stack([\n",
    "            list(decoding_accuracy.query(f\"network == '{dnn_name}' & layer == '{lay}' & roi == '{roi}'\")[\"accuracy\"])[0]\n",
    "            for roi in rois\n",
    "        ])\n",
    "        dec_pred_acc.append(df)\n",
    "\n",
    "    makefig_top_roi_distribution(dec_pred_acc, dnn['layers'], dnn_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
